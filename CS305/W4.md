# Blog post 4: Deepfakes
_A report on the fake news generating software_<br/><br/>

**By Yves Wienecke** <br />
January 20, 2019

## What is a deep fake?
A deep fake is a type of digital impersonation that takes in video source input
to produce an output video where the face of a subject is replaced with a machine learning
generated face of a different subject. It's similar to the face swap app popularized on snapchat,
but does a bit more work to make the swap appear more realistic, such matching face angle and
blinking. Take this video of American acress Jennifer Lawrence with her face swapped with actor 
Steve Buscemi, for example:<br /> <br/>

<iframe width="560" height="315" src="https://www.youtube.com/embed/O7JOD-qytb8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br />
_[Vecanoi] A stunningly realistic video of Jeniffer Lawrence with Steve Buscemi's face._<br /><br/>


## How does it work?
The first step is to creating a deepfake is to parse through a database of images of a subject (using google or bing search)
and perform a sequence of tranformations on the images to create a basic representation of the image and
crop out the faces of each image. This is repeated with another subject so that there are two sets of faces.
Then, a two convolutional networks are trained on each respected set. First, the networks use the same type
of autoencoder, which transforms the input face into a basic representation of the face. Then, the networks
each use their own special decoder to generate the original face as realistically as possible.

After training is complete, an image of the first subject's face can be encoded by the first convolutional network
and then decoded by the second network to generate the second subject's face. In this way, a basic representation
of a face is a transition language, such as translating from hex to binary to decimal, or from java to bytecode to
assembly, with binary and bytecode being the transitional languages.

Finally, the convoluted neural network can be given a video of only the first subject, and then can change every single
frame in this input video to generate an output version where the first subject's face is swapped with the second
subject's face.<Br/><br/>

<iframe width="560" height="315" src="https://www.youtube.com/embed/7XchCsYtYMQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br/>
_[Raval] Explanation of how deepfakes work._<br/><br/>


## Progression of how technology got to this point
Researchers in the field of computer vision have make baffling progress over just the past two years. For me, it 
all started in 2017, when I came to know about 'pix2pix,' which takes a crude drawing of something like 
a cat, face, or shoe, and tries to create a realistic version of the drawing. However, the generated images were
commonly hideous and nightmare-inducing, so it wasn't particularly realistic [Hesse].<Br/><br/>

A couple months later, researchers were able to produce a video of Obama 'saying' something by syncing lip
movement to an audio input. Why Obama? Well, there is a lot of training data - that is, his weekly adress
videos.<br/>

<iframe width="560" height="315" src="https://www.youtube.com/embed/nsuAQcvafCs" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br/>
_[Papers] Generated video of Obama 'saying' things._<br/><br/>

Researchers developed video-to-video generation about a year later, where a video labels various objects
in an input video such that the labels can be turned into various objects, like trees or buildings. This
allowed for creating variations on a video by changing backdrop or time of day.<br/>

<iframe width="560" height="315" src="https://www.youtube.com/embed/GRQuRcpf5Gc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br/>
_[Papers2] Video-to-video synthesis._<br/><br/>

Fast forward to a few months ago, machine learning could take a 2D input image and mapped the image to
a 3D model, allowing the input image to be manipulated throughout 3D space. This opens up a world of
possibilities for creative inspiration, but at the same time reminds of the power that software has.<br/>

<iframe width="560" height="315" src="https://www.youtube.com/embed/AGm3hF_BlYM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br/>
_[Papers3] Making a 3D model from a 2D image._<Br/><br/>

With this in mind, the creation of deepfakes does not surprise me. What does surprise me, however, is hard
it is to spot a deepfake - they certainly do a good job at resembling the training input. This point 
was brought to the attention of the public after buzzfield released a video of supposedly Obama
giving a statement:<br /><br />

<iframe width="560" height="315" src="https://www.youtube.com/embed/cQ54GDm1eL0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><br/>
_[BuzzFeed] Top comment: "Wow, Barack Obama does a mean Jordan Peele impersonation"_<br/><br/>

## Possible positive uses for it


## What is it actually used for? porn, nic cage memes, fake news

## What impact social, legal does it have on public?


<br /><br /><br /><br />

<hr>

## Sources

[Vecanoi] Vecanoi. "Original video + Stennifer Lawrscemi." _Youtube,_ 31 Jan. 2019, [https://www.youtube.com/watch?v=O7JOD-qytb8](https://www.youtube.com/watch?v=O7JOD-qytb8).<br />
[Raval] Ravel, Siraj. "DeepFakes Explained." _Youtube,_ 2 Feb. 2019, [DeepFakes Explained](DeepFakes Explained).<br/>
[Hesse] Hesse, Christopher. "Image-to-Image Demo." _Affine Layer,_ 19 Feb. 2017, [https://affinelayer.com/pixsrv/](https://affinelayer.com/pixsrv/).<br/>
[Papers] Two Minute Papers. "Audio To Obama: AI Learns Lip Sync from Audio | Two Minute Papers #194." *Youtube,* 4 Oct. 2017, [https://www.youtube.com/watch?v=nsuAQcvafCs](https://www.youtube.com/watch?v=nsuAQcvafCs).<br/>
[Papers2] Two Minute Papers. "AI-Based Video-to-Video Synthesis." *Youtube,* 9, Sep. 2018, [https://www.youtube.com/watch?v=GRQuRcpf5Gc](https://www.youtube.com/watch?v=GRQuRcpf5Gc).<br/>
[Papers3] Two Minute Papers. "This AI Learns Human Movement From Videos." *Youtube,* 6, Dec. 2018, [https://www.youtube.com/watch?v=AGm3hF_BlYM](https://www.youtube.com/watch?v=AGm3hF_BlYM).<br/>
[BuzzFeed] BuzzFeedVideos. "You Wonâ€™t Believe What Obama Says In This Video! ðŸ˜‰." *Youtube,* 17 Apr. 2018, [https://www.youtube.com/watch?v=cQ54GDm1eL0](https://www.youtube.com/watch?v=cQ54GDm1eL0).<br/><br/>

